{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Wrangling Project\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "O OpenStreetMap (OSM) é um projeto *open source* que procura criar um mapa gratuito do mundo inteiro a partir de dados inseridos voluntariamente. É um esforço colaborativo com mais de 2 milhões de contribuidores. Os dados do OpenStreetMap estão disponíveis gratuitamente para *download* em muitos formatos, e representam uma excelente oportunidade para praticar *Data Science* pois:\n",
    "- Todo o conjunto de dados é gerado pelo usuário, significando que haverá uma quantidade significativa de dados \"sujos\";\n",
    "- O conjunto de dados é para qualquer área é gratuito para baixar em muitos formatos, incluindo XML;\n",
    "- Os dados são confiáveis e compreensíveis pelo ser humano porque representam lugares e recursos reais.\n",
    "\n",
    "### 1.1 Objetivo do projeto\n",
    "\n",
    "O objetivo deste projeto é obter dados do mapa de uma região do mundo; auditar os dados; corrigir os problemas encontrados; importar os dados em um banco de dados (nesse caso um banco de dados NoSQL, **MongoDB**) e executar algumas consultas exploratórias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Coleta e Auditoria de Dados\n",
    "\n",
    "### 2.1 Escolha do mapa\n",
    "\n",
    "Decidi trabalhar com a área de Campinas, porque é onde eu atualmente moro. Os dados de Campinas usados para este projeto foram obtidos no OpenStreetMap e baixados seguinte link: https://www.openstreetmap.org/relation/298227\n",
    "\n",
    "Algumas características desses dados são apresentadas abaixo:\n",
    "\n",
    "<img src=\"map.png\" />\n",
    "\n",
    "### 2.2 Exploração preliminar dos dados\n",
    "\n",
    "O primeiro passo foi baixar o mapa como um arquivo XML utilizando a API Overpass, conforme mostrado abaixo:\n",
    "\n",
    "<img src=\"map2.png\" />\n",
    "\n",
    "Existem três elementos principais de nível superior no OSM, como pode-se verificar no código abaixo:\n",
    "1. `'Nodes'` representam um único ponto e possuem id, latitude e longitude. Eles também podem conter *tags* descritivas no `'node'` se estiverem em um item de interesse;\n",
    "2. `'Ways'` são constituídas por listas ordenadas de nós que descrevem uma característica linear, como uma trilha ou uma área como um parque. Eles contêm uma lista dos nós que compõem o caminho, bem como tags para informações detalhadas;\n",
    "3. `'Relations'` são constituídas por uma lista ordenada de membros que podem ser `'nodes'` ou `'ways'`. Eles são usados para representar relações lógicas ou geográficas entre recursos e conter uma lista de membros, bem como *tags* que descrevem o elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias para a análise\n",
    "\n",
    "from xml.sax.handler import ContentHandler\n",
    "from xml.sax import make_parser\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import pprint\n",
    "import re\n",
    "import unicodedata\n",
    "import pycep_correios # Biblioteca dos Correios para consulta de CEP\n",
    "import codecs\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pymongo import GEO2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map.os is a XML file well-formed\n"
     ]
    }
   ],
   "source": [
    "''' Começando pelo começo: verificando se o arquivo OSMFILE é um arquivo XML válido. '''\n",
    "\n",
    "file = \"map.os\" # É necessário descompactar o arquivo map.os.zip antes de iniciar a análise\n",
    "\n",
    "def parse_file(file):\n",
    "    \"\"\" Verifica se um determinado arquivo possui estrutura XML parseável.\n",
    "    Args:\n",
    "        file: arquivo a ser verificado.\n",
    "    Raises:\n",
    "        Exception: caso o arquivo não seja XML parseável.\n",
    "    \"\"\"\n",
    "    osm_file = open(file, \"r\")\n",
    "    parser = make_parser()\n",
    "    parser.parse(osm_file)\n",
    "    osm_file.close()\n",
    "    \n",
    "try:\n",
    "    parse_file(file)\n",
    "    print(\"%s is a XML file well-formed\" % file)\n",
    "except (Exception, e):\n",
    "    print(\"%s is NOT a XML file well-formed! %s\" % (file, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 5430,\n",
      " 'meta': 1,\n",
      " 'nd': 343980,\n",
      " 'node': 269600,\n",
      " 'note': 1,\n",
      " 'osm': 1,\n",
      " 'relation': 467,\n",
      " 'tag': 120097,\n",
      " 'way': 42004}\n"
     ]
    }
   ],
   "source": [
    "''' Olhando dentro da estrutura do XML.'''\n",
    "\n",
    "def process_file(file):\n",
    "    \"\"\" Processa um arquivo XML e retorna quais são as tags únicas e suas contagens\n",
    "    Args:\n",
    "        file: arquivo a ser processado.\n",
    "    Returns:\n",
    "        Um conjunto de tags únicas encontradas no arquivo e suas respectivas contagens.\n",
    "    \"\"\"\n",
    "    osm_file = open(file, \"r\")\n",
    "    xml_tags = {}\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag in xml_tags: # Se elemento já existe no conjunto, adiciona contagem\n",
    "            xml_tags[elem.tag] += 1\n",
    "        else: # Caso contrário, adiciona elemento e inicia com 1 contagem\n",
    "            xml_tags[elem.tag] = 1\n",
    "    osm_file.close()\n",
    "    return xml_tags\n",
    "\n",
    "result = process_file(file)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 114844, 'lower_colon': 5171, 'other': 82, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "''' Validando os atributos k do elemento tag, para ver se haverá algum problema ao carregar os dados no MongoDB'''\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$') # Matches strings containing lower case characters\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$') # Matches strings containing lower case characters and a single colon within the string\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]') # Matches characters that cannot be used within keys in MongoDB\n",
    "\n",
    "def key_type(element, keys):\n",
    "    \"\"\" Processa os elementos XML e seus atributos k buscando por caracteres \n",
    "    problemáticos para o MongoDB.\n",
    "    Args:\n",
    "        elem: elemento XML.\n",
    "        keys: conjunto de chaves.\n",
    "    Returns:\n",
    "        Um conjunto de tags únicas encontradas no arquivo e suas respectivas contagens.\n",
    "    \"\"\"\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.get('k')\n",
    "            if lower.search(k):\n",
    "                keys['lower'] += 1\n",
    "            elif lower_colon.search(k):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif problemchars.search(k):\n",
    "                keys['problemchars'] += 1\n",
    "            else:\n",
    "                keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "def process_keys(file):\n",
    "    osm_file = open(file, \"r\")\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(osm_file):\n",
    "        keys = key_type(element, keys)\n",
    "    osm_file.close()\n",
    "    return keys\n",
    "\n",
    "keys = process_keys(file)\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode-se observar pelo resultado, nenhum problema foi encontrado no arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Identificando os usuários únicos'''\n",
    "\n",
    "def process_users(file):\n",
    "    \"\"\" Encontra o número de usuários únicos em um arquivo OSMFILE.\n",
    "    Args:\n",
    "        file: arquivo XML a ser processado.\n",
    "    Returns:\n",
    "        Número de usuários únicos.\n",
    "    \"\"\"\n",
    "    osm_file = open(file, \"r\")\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(osm_file):\n",
    "        for e in element:\n",
    "            if 'user' in e.attrib:\n",
    "                users.add(e.attrib['user'])\n",
    "    osm_file.close()\n",
    "    return users\n",
    "\n",
    "users = process_users(file)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No arquivo selecionado, foram encontrados 537 usuários únicos que contribuíram para os dados do OSMFILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation {'relation', 'tag', 'member'}\n",
      "meta {'meta'}\n",
      "note {'note'}\n",
      "way {'nd', 'tag', 'way'}\n",
      "osm {'note', 'osm', 'node', 'meta', 'tag', 'bounds'}\n",
      "nd {'nd'}\n",
      "member {'member'}\n",
      "tag {'tag'}\n",
      "bounds {'bounds'}\n",
      "node {'tag', 'node'}\n"
     ]
    }
   ],
   "source": [
    "''' Descobrindo quais são as tags únicas.'''\n",
    "\n",
    "def process_tags(file, tag):\n",
    "    \"\"\" Encontra as subtags únicas dentro de uma determinada tag.\n",
    "    Args:\n",
    "        file: arquivo XML a ser processado.\n",
    "        tag: tag a ser verificada.\n",
    "    Returns:\n",
    "        Subtags únicas.\n",
    "    \"\"\"\n",
    "    osm_file = open(file, \"r\")\n",
    "    subtag_types = set() # Criando um set, pois gostaria de ver todas as subtags das tags.\n",
    "    for event, element in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if element.tag == tag:\n",
    "            for subelem in element.iter():\n",
    "                subtag_types.add(subelem.tag)\n",
    "    osm_file.close()\n",
    "    return subtag_types\n",
    "\n",
    "for i in result:\n",
    "    subtags = process_tags(file,i)\n",
    "    print(i,subtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que apenas as tags `relation`, `node`, `way` possuem uma estrutura com sub-elementos, assim como o próprio elemento *root* `osm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 *Data Cleaning Process*\n",
    "Estar no controle de um grande conjunto de dados pode ser excitante e intimidante! Existem inúmeras possibilidades de exploração, mas a grande quantidade de informações pode ser esmagadora. Antes de iniciar oficialmente qualquer análise de dados, é importante ter um plano para passar eficientemente pelo processo de auditoria e limpeza dos dados.A seguinte abordagem é bastante interessante, foi adaptada do curso Udacity sobre Data Wrangling:\n",
    "1. Auditar os dados: identificar erros/dados em falta ou geralmente \"sujos\" no arquivo XML original;\n",
    "2. Criar um plano de limpeza de dados com base na auditoria:\n",
    "    - Identificar as causas de dados inconsistentes/incorretos;\n",
    "    - Desenvolver um conjunto de ações de limpeza corretivas e teste em uma pequena amostra dos dados XML;\n",
    "3. Implementar o plano de limpeza de dados: executando scripts de limpeza e transfira os dados limpos para arquivos .csv;\n",
    "4. Corrijir manualmente conforme necessário: importando os dados dos arquivos .csv para um banco de dados NoSQL (ou, alternativamente, para um banco de dados SQL) e executando consultas nos dados para identificar quaisquer inconsistências adicionais que exijam o retorno ao passo 1.\n",
    "\n",
    "A análise de dados é um procedimento iterativo e, como tal, é esperado trabalhar várias vezes com essas etapas. Além disso, é sempre bom ter um esboço claro do procedimento para não se perder no meio da análise.\n",
    "\n",
    "### 2.3.1 Qualidade dos dados\n",
    "Existem cinco aspectos principais da qualidade dos dados a serem considerados ao auditar um conjunto de dados:\n",
    "1. **Validade**: os dados estão em conformidade com um formato padrão?\n",
    "2. **Precisão**: os dados concordam com a realidade ou com uma fonte externa confiável? \n",
    "3. **Completude**: todos os registros estão presentes?\n",
    "4. **Consistência**: os dados estão em um campo ou em uma linha em acordo lógico? \n",
    "5. **Uniformidade**: as mesmas unidades são usadas para um determinado campo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Auditando e Limpando os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street types\n",
    "\n",
    "Outra auditoria que eu poderia realizar para validade, bem como consistência, dizia respeito aos nomes das ruas associados ao nó e à tag. A partir do meu exame exploratório inicial dos dados, notei uma grande variedade de terminais e abreviaturas de nomes de ruas. Usando um script de auditoria de nome de rua provisório, eu comparei os terminais de rua com uma lista padronizada e contei o número de vezes que cada tipo não padrão apareceu usando a seguinte função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets in the wrong format:\n",
      "defaultdict(<class 'set'>,\n",
      "            {'Antônio': {'Antônio Ferreira'},\n",
      "             'Av': {'Av José Rocha Bomfim'},\n",
      "             'Av.': {'Av. Cabo Pedro Hoffman',\n",
      "                     'Av. Doutor Armando de Ottaviano',\n",
      "                     'Av. Doutor Moraes Sales',\n",
      "                     'Av. Francisco Sáles Píres',\n",
      "                     'Av. James Clark Maxwell',\n",
      "                     'Av. José Rocha Bomfim',\n",
      "                     'Av. Maria Ferreira Antunes',\n",
      "                     'Av. Mirandópolis'},\n",
      "             'Campos': {'Campos Salles'},\n",
      "             'Cecília': {'Cecília Feres Zogbi'},\n",
      "             'Doutor': {'Doutor Bonifácio de Castro Filho'},\n",
      "             'José': {'José Orides Cordeiro'},\n",
      "             'Plínio': {'Plínio Pereira da Cruz'},\n",
      "             'R.': {'R. Benedito Cândido Ramos',\n",
      "                    'R. Flambolant',\n",
      "                    'R. Osvaldo Ribeiro Carrilho'},\n",
      "             'Romeu': {'Romeu Chiminasso'},\n",
      "             'Rua.': {'Rua. Laércio de Oliveira'},\n",
      "             'SP-332': {'SP-332'},\n",
      "             'das': {'das Castanheiras', 'das Pitangueiras'},\n",
      "             'rua': {'rua Mato grosso 58 monte mor sp',\n",
      "                     'rua Vitor Baranauska Filho.N.125.',\n",
      "                     'rua bernardo de souza campos'}})\n"
     ]
    }
   ],
   "source": [
    "''' Auditando os tipos de ruas presentes na região escolhida.'''\n",
    "\n",
    "street_type_re = re.compile(r'^\\S+\\.?(\\b)?', re.IGNORECASE) # Regex para pegar a primeira palavra (https://regex101.com)\n",
    "\n",
    "expected = [\"Acesso\", \"Alameda\", \"Avenida\", \"Beco\", \"Boulevard\", \"Caminho\",\n",
    "    \"Campo\", u\"Condomínio\", \"Estrada\", \"Ladeira\", \"Largo\", \"Parque\", u\"Praça\",\n",
    "    \"Praia\", \"Rodovia\", \"Rua\", \"Travessa\", \"Via\"]\n",
    "\n",
    "mapping = { \"Av\": \"Avenida\",\n",
    "            \"Av.\": \"Avenida\",\n",
    "            \"Est.\": \"Estrada\",\n",
    "            \"Estr.\": \"Estrada\",\n",
    "            \"estrada\": \"Estrada\",\n",
    "            \"Pca\": u\"Praça\",\n",
    "            \"Praca\": u\"Praça\",\n",
    "            u\"Pça\": u\"Praça\",\n",
    "            u\"Pça.\": u\"Praça\",\n",
    "            \"R.\": \"Rua\",\n",
    "            \"Rua.\": \"Rua\",\n",
    "            \"RUA\": \"Rua\",\n",
    "            \"rua\": \"Rua\",\n",
    "            \"Ruas\": \"Rua\",\n",
    "            \"Rue\": \"Rua\",\n",
    "            \"Rod.\": \"Rodovia\",\n",
    "            \"Trav\": \"Travessa\" }\n",
    "\n",
    "def update_street_name(name, mapping):\n",
    "    \"\"\" Atualiza o nome da rua utilizando um dicionário.\n",
    "    Args:\n",
    "        name: nome da rua.\n",
    "        mapping: dicionário.\n",
    "    Returns:\n",
    "        Nome corrigido.\n",
    "    \"\"\"\n",
    "    m = street_type_re.search(name)\n",
    "    street_type = m.group()\n",
    "    if street_type in mapping:\n",
    "        name = street_type_re.sub(mapping[street_type], name).title()\n",
    "        name = name.replace(\"De\", \"de\") # Corrigindo o \"De\" para \"de\" depois de ter aplicado title()\n",
    "    return name\n",
    "\n",
    "def audit_street_name(street_types, street_name):\n",
    "    \"\"\" Audita um nome de rua.\n",
    "    Args:\n",
    "        street_types: dicionário com os tipos de ruas.\n",
    "        street_name: nome da rua.\n",
    "    Returns:\n",
    "        Nome corrigido.\n",
    "    \"\"\"\n",
    "    street_name = street_name.replace(\"Dr.\", \"Doutor\") # Cleanup do Dr. para Doutor para uniformidade dos nomes.\n",
    "    m = street_type_re.search(street_name) # Cria os grupos do dicionário\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected: # Adiciona ocorrência não esperada ao grupo\n",
    "            street_types[street_type].add(street_name)\n",
    "            street_name = update_street_name(street_name, mapping)\n",
    "            #print(street_name)\n",
    "    return street_name\n",
    "\n",
    "def audit_street(osmfile):\n",
    "    \"\"\" Audita todos os nomes de ruas de um arquivo OSMFILE.\n",
    "    Args:\n",
    "        osmfile: arquivo XML do OpenStreetMap.\n",
    "    Returns:\n",
    "        Dicionário com todos os tipos de ruas.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    audit_street_name(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "st_types = audit_street(file)\n",
    "print(\"Streets in the wrong format:\")\n",
    "pprint.pprint(st_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descobertas**: aqui notamos que o uso de abreviações, como Av. e R. são as maiores ocorrências de tipo de rua que desviam do esperado. O uso de letras minúsculas ao invés de maiúsculas para o nome das ruas e avenidas também indica uma inconsistência, como a `rua bernardo de souza campos` e `Rua Bernardo de Souza Campos`, que representam a mesma rua. Além disso, existem nomes sem a determinação do tipo de rua (para esses últimos vamos deixar assim como está, mas que poderia ser corrigida uma a uma). \n",
    "\n",
    "**Correções**: As correções necesárias são sobre o tipo de rua e ruas que estão escritas em *lowercase*. As demais correções serão deixadas como trabalhos futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código Postal\n",
    "Uma auditoria adicional que eu poderia realizar para verificar a precisão estava nos códigos postais. A minha abordagem com os códigos postais foi comparar os códigos postais encontrados com o serviço disponibilizado pelos Correios, bem como uniformizá-los. O código a seguir foi usado para executar a auditoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postal codes in the wrong format:\n",
      "{'13', '1318-103', '1314244'}\n"
     ]
    }
   ],
   "source": [
    "''' Auditando os tipos de CEPs presentes na região escolhida'''\n",
    "\n",
    "postal_code_type_re = re.compile(r'^\\d{2}[\\.]?[0-9]{3}[\\-\\s]?[0-9]{3}', re.IGNORECASE) # Regex para pegar os CEPs no formato aceito no Brasil\n",
    "\n",
    "def update_postal_code(code):\n",
    "    \"\"\" Atualiza a formatação do CEP.\n",
    "    Args:\n",
    "        code: CEP.\n",
    "    Returns:\n",
    "        CEP corrigido.\n",
    "    \"\"\"\n",
    "    for ch in ['.','-']:\n",
    "        code=code.replace(ch,'') # Remove pontos e traços nos CEPs (coisa simples)\n",
    "    return code\n",
    "\n",
    "def audit_postal_code(osmfile):\n",
    "    \"\"\" Audita todos códigos postais de um arquivo OSMFILE no formato brasileiro.\n",
    "    Args:\n",
    "        osmfile: arquivo XML do OpenStreetMap.\n",
    "    Returns:\n",
    "        Dicionário com todos os tipos de CEPs bons e um outro dicionário com todos\n",
    "        os tipos de CEPs ruins.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    postal_codes = set()\n",
    "    bad_zips = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == 'tag':\n",
    "            if 'postal_code' in elem.attrib['k'] or 'addr:postcode' in elem.attrib['k']:\n",
    "                zip_code = elem.attrib['v']\n",
    "                test = postal_code_type_re.search(zip_code)\n",
    "                if test:\n",
    "                    postal_codes.add(zip_code)\n",
    "                else:\n",
    "                    bad_zips.add(zip_code)\n",
    "    osm_file.close()\n",
    "    return postal_codes, bad_zips\n",
    "\n",
    "cep_types, cep_problematic = audit_postal_code(file)\n",
    "\n",
    "print(\"Postal codes in the wrong format:\")\n",
    "pprint.pprint(cep_problematic)\n",
    "\n",
    "# Verificando, por exemplo, se todos os CEPs são de Campinas\n",
    "# Pode-se elaborar mais, verificando se o endereço das tags com CEP bate com o endereço registrado nos Correios\n",
    "#for cep in cep_types:\n",
    "    #endereco = pycep_correios.consultar_cep(cep)\n",
    "    #assert endereco['cidade'] == 'Campinas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descobertas**: Há poucas informações sobre o CEP, mas as informações encontradas batem com o esperado. Por exemplo, o CEP 13035-110 corresponde à `Rua Ernesto Segalho` e o CEP corresponde à `Rua Odila Santos de Souza Camargo`, ou seja, são CEPs existentes, são de Campinas, e as ruas dessas tags são as mesmas das esperadas. Para verificar em massa os CEPs em cidades do Brasil, recomenda-se o uso da biblioteca `pycep-correios` (https://pypi.python.org/pypi/pycep-correios/2.2.0) dos Correios, e que seja executado fora do laço de iteração de verificação das tags, pois a consulta aos Correios acaba tomando um tempinho que, dependendo do tamanho do arquivo OSMFILE, poderia levar muito tempo.\n",
    "\n",
    "**Correções**: Exceto pelas três ocorrências, todos os CEPs atendem ao padrão Brasileiro, então nenhuma correção será necessária (como trabalho futuro, o que poderia ser feito é corrigir cada um dos códigos postais problemáticos usando como base as informações de endereço do respectivo elemento). No entanto, para deixar tudo certinho vamos eliminar os `\".\"` e `\"-\"` e uniformizar os CEPs. Como trabalho futuro, pode-se montar uma relação com todos os CEPs de Campinas e região e complementar o arquivo XML com essa informação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de telefone\n",
    "\n",
    "Em diversas aplicações, é importante padronizar o número de telefone. E com bastante frequência cada usuário coloca o telefone de um jeito. Assim, é possível automatizar ligações, envios de mensagens, SMS, organizar os contatos para a equipe de vendas, etc. É o que será feito abaixo, vamos ver quais os formatos de telefone no arquivo e vamos corrigir e padronizar para que os números de telefone contenham o formato +55 + número sem ou com o DDD (sem o zero). Essa parte é particularmente importante, especialmente pois varia muito de pessoa a pessoa como registrar o número de telefone e, principalemente, porque depois podemos usar essa informação de diversas formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phones in the wrong format:\n",
      "{'(19) 2103-9166',\n",
      " '(19) 2137 6803',\n",
      " '(19) 2137-0600',\n",
      " '(19) 2512-0304',\n",
      " '(19) 3202 5700',\n",
      " '(19) 3203 0101',\n",
      " '(19) 3231 2022',\n",
      " '(19) 3231 2121',\n",
      " '(19) 3231 4290',\n",
      " '(19) 3231-5436',\n",
      " '(19) 3233 7085',\n",
      " '(19) 3236 1222',\n",
      " '(19) 3236 9800',\n",
      " '(19) 3253-7364',\n",
      " '(19) 3256-8689',\n",
      " '(19) 3256-8799',\n",
      " '(19) 3277-0064',\n",
      " '(19) 3294 3892',\n",
      " '(19) 3296-5412',\n",
      " '(19) 3327-2574',\n",
      " '(19) 3519 3829',\n",
      " '(19) 3731 2430',\n",
      " '(19) 3734 3000',\n",
      " '(19) 3736 9500',\n",
      " '(19) 3737-4390',\n",
      " '(19) 3739 3004',\n",
      " '(19) 3739 8888',\n",
      " '(19) 3753-2400',\n",
      " '(19) 3755-8000',\n",
      " '(19) 3773 9000',\n",
      " '(19) 3829-5120',\n",
      " '(19) 3845 2015',\n",
      " '(19) 3845 2672',\n",
      " '(19) 3869-3900',\n",
      " '(19) 3897 1900',\n",
      " '(19) 98128-8127',\n",
      " '+55  19 3844 8532',\n",
      " '+55 (19) 2121-1921',\n",
      " '+55 (19) 3521-4608',\n",
      " '+55 (19) 3794-4444',\n",
      " '+55 019 3281 5739',\n",
      " '+55 019 3282 1434',\n",
      " '+55 11 3093-0816',\n",
      " '+55 11 3865 2572',\n",
      " '+55 11 4538-0055',\n",
      " '+55 11 4538-6474',\n",
      " '+55 19  3838 5785',\n",
      " '+55 19  3874 2070',\n",
      " '+55 19 2118 6000',\n",
      " '+55 19 2121-8461',\n",
      " '+55 19 2511 0588',\n",
      " '+55 19 2513-0762',\n",
      " '+55 19 30271066',\n",
      " '+55 19 3114 6300',\n",
      " '+55 19 3116 1000',\n",
      " '+55 19 3208-2028;+55 19 3386-1821',\n",
      " '+55 19 3212-3537',\n",
      " '+55 19 3223 7377',\n",
      " '+55 19 3224 0955',\n",
      " '+55 19 3224 1638',\n",
      " '+55 19 3225-9929',\n",
      " '+55 19 3226 0048',\n",
      " '+55 19 3226 5171',\n",
      " '+55 19 3226 5587',\n",
      " '+55 19 3226 6569',\n",
      " '+55 19 3227 0016',\n",
      " '+55 19 3231-3387',\n",
      " '+55 19 32315929',\n",
      " '+55 19 3232 4106',\n",
      " '+55 19 3246 2888',\n",
      " '+55 19 3246 3055',\n",
      " '+55 19 3252 2598',\n",
      " '+55 19 32525332',\n",
      " '+55 19 3254-3519',\n",
      " '+55 19 32544590',\n",
      " '+55 19 32547606',\n",
      " '+55 19 32550683',\n",
      " '+55 19 32554884',\n",
      " '+55 19 3256 9959',\n",
      " '+55 19 3256-6565',\n",
      " '+55 19 3256-6722',\n",
      " '+55 19 3265 0103',\n",
      " '+55 19 3266 6076',\n",
      " '+55 19 3266 6965',\n",
      " '+55 19 3266 8668',\n",
      " '+55 19 3276-5211',\n",
      " '+55 19 32780637',\n",
      " '+55 19 3279-1516',\n",
      " '+55 19 328 16973',\n",
      " '+55 19 3281 0100',\n",
      " '+55 19 3281 1080',\n",
      " '+55 19 3281 1855',\n",
      " '+55 19 3281 1979',\n",
      " '+55 19 3281 3170',\n",
      " '+55 19 3282 0024',\n",
      " '+55 19 3282 5065',\n",
      " '+55 19 3289-1011',\n",
      " '+55 19 3289-5369, +55 3249-1510',\n",
      " '+55 19 3294 6307',\n",
      " '+55 19 3295-5344',\n",
      " '+55 19 3295-9058',\n",
      " '+55 19 3298-6249',\n",
      " '+55 19 3298-6289',\n",
      " '+55 19 3303 3500',\n",
      " '+55 19 3304-5833',\n",
      " '+55 19 3305-2947',\n",
      " '+55 19 3306 2050',\n",
      " '+55 19 3306 3525',\n",
      " '+55 19 3322-4000',\n",
      " '+55 19 3343-8600',\n",
      " '+55 19 33672005',\n",
      " '+55 19 3368-2956',\n",
      " '+55 19 33817012',\n",
      " '+55 19 33995700',\n",
      " '+55 19 3521-5921',\n",
      " '+55 19 3521-7701',\n",
      " '+55 19 3716 8680',\n",
      " '+55 19 3723 2000',\n",
      " '+55 19 3726 2000',\n",
      " '+55 19 3728-4000',\n",
      " '+55 19 3733-8800',\n",
      " '+55 19 37392100',\n",
      " '+55 19 3743-7001',\n",
      " '+55 19 3744 2000',\n",
      " '+55 19 3746-6128',\n",
      " '+55 19 37497333',\n",
      " '+55 19 3751 4180',\n",
      " '+55 19 37538000',\n",
      " '+55 19 3754 6300',\n",
      " '+55 19 3758 4400',\n",
      " '+55 19 3795 4150',\n",
      " '+55 19 3809 6300',\n",
      " '+55 19 3809 9800',\n",
      " '+55 19 3819 1455',\n",
      " '+55 19 3819 1569',\n",
      " '+55 19 3819 1645',\n",
      " '+55 19 3819 3056',\n",
      " '+55 19 3833 4030',\n",
      " '+55 19 3837 8800; +55 19 3837 8500; +55 19 3867 1451',\n",
      " '+55 19 3837 8800;+55 19 3837 8500;+55 19 3867 1451',\n",
      " '+55 19 3838 2112',\n",
      " '+55 19 3838 8900',\n",
      " '+55 19 3844 5573',\n",
      " '+55 19 3847 8000',\n",
      " '+55 19 3854 3666',\n",
      " '+55 19 3864 0500',\n",
      " '+55 19 3864 1034',\n",
      " '+55 19 3865 1284',\n",
      " '+55 19 3865 2571',\n",
      " '+55 19 3865 2574',\n",
      " '+55 19 3865 4563',\n",
      " '+55 19 3874 1836',\n",
      " '+55 19 3874 3090',\n",
      " '+55 19 3874 4888',\n",
      " '+55 19 3874 9366',\n",
      " '+55 19 3884 3269',\n",
      " '+55 19 3887 1167',\n",
      " '+55 19 3887 1311',\n",
      " '+55 19 3887 1461',\n",
      " '+55 19 3887 1546',\n",
      " '+55 19 3887 1569',\n",
      " '+55 19 3887 1680',\n",
      " '+55 19 3887 1770',\n",
      " '+55 19 3887 2329',\n",
      " '+55 19 3887 2563',\n",
      " '+55 19 3887 2955',\n",
      " '+55 19 3887 4992',\n",
      " '+55 19 3887 5777',\n",
      " '+55 19 3897 1415',\n",
      " '+55 19 3897 1446',\n",
      " '+55 19 3897 1447',\n",
      " '+55 19 3897 3727',\n",
      " '+55 19 3897 3933',\n",
      " '+55 19 3897 5935',\n",
      " '+55 19 3897 8410',\n",
      " '+55 19 3909 0505',\n",
      " '+55 19 3909 0616',\n",
      " '+55 19 3909 1718',\n",
      " '+55 19 3909 6767',\n",
      " '+55 19 3909 9000',\n",
      " '+55 19 3909 9033',\n",
      " '+55 19 3909 9050',\n",
      " '+55 19 3909 9070',\n",
      " '+55 19 4062 0086',\n",
      " '+55 19 41221911',\n",
      " '+55 19 97 1423 882',\n",
      " '+55 1932667798',\n",
      " '+55(19) 3231-2513',\n",
      " '+55(19) 3231-2830',\n",
      " '+55(19) 3253-7717',\n",
      " '+55-19-32727000',\n",
      " '+55-19-3342-2797',\n",
      " '+55-19-3395-0366',\n",
      " '+55019-3246-0077',\n",
      " '+5519 32522986',\n",
      " '+5519 3282 6478;+55 19 3281 6635',\n",
      " '+5519 3287-4343',\n",
      " '+5519 3579-9040',\n",
      " '+5519 37058027',\n",
      " '+55193294-1437',\n",
      " '019 3231 3737',\n",
      " '019 3231 4715',\n",
      " '019 3243 5811',\n",
      " '019 3243 9722',\n",
      " '019 3254 4010',\n",
      " '019 3255 0133',\n",
      " '019 3306 6000',\n",
      " '019 99123 9162',\n",
      " '01933273460',\n",
      " '0800 109 788',\n",
      " '0800 772 36 33',\n",
      " '160',\n",
      " '19 32035559',\n",
      " '19 32171170',\n",
      " '19 3236 1801',\n",
      " '19 32524598',\n",
      " '19 3305 1536',\n",
      " '19 3305 6435',\n",
      " '1932320831',\n",
      " '1938334760',\n",
      " '193869-1700',\n",
      " '19991041005',\n",
      " '19995540511',\n",
      " '32278600',\n",
      " '37566893',\n",
      " '3837-3329',\n",
      " '3837-4576',\n",
      " '38766900',\n",
      " '4090-1030 para capitais e regiões metropolitanas e 0800-883-2000 para demais '\n",
      " 'regiões',\n",
      " '55 (19) 9211-7898',\n",
      " '55 19 3778-3000',\n",
      " '551932010998',\n",
      " '55193833-4760'}\n"
     ]
    }
   ],
   "source": [
    "''' Auditando os tipos de telefones presentes na região escolhida. Essa parte é particularmente importante,\n",
    "especialmente pois varia muito de pessoa a pessoa como registrar o número de telefone e, principalemente,\n",
    "porque depois podemos usar essa informação de diversas formas.'''\n",
    "\n",
    "phone_type_re = re.compile(r'(?:[+]55)(?:([0-9]{2}))?(?:([0-9]{1}[0-9]{6,8}[0-9]))', re.IGNORECASE) # Regex para validar telefones no formato +55dddxxxxxxxxx ou +55xxxxxxxxx para ficar certo para uso em aplicações\n",
    "number_re = re.compile(r'^\\D*(\\d+)', re.IGNORECASE) # Regex para pegar a primeira ocorrência de número em uma string\n",
    "\n",
    "def update_phone_value(phone):\n",
    "    \"\"\" Atualiza o número de telefone no padrão brasileiro.\n",
    "    Args:\n",
    "        phone: número de telefone.\n",
    "    Returns:\n",
    "        Telefone corrigido no padrão brasileiro.\n",
    "    \"\"\"\n",
    "    for ch in [' ','-','(',')']: # Remove espaços, traços e parênteses\n",
    "        phone=phone.replace(ch,'')\n",
    "    m = number_re.search(phone) # Remove strngs se houver\n",
    "    phone = m.group()\n",
    "    if phone.startswith('0') and not phone.startswith('0800'): # Se começar com 0 e não for 0800, tira o zero\n",
    "        phone = phone[len('0'):]\n",
    "        phone = \"+55\"+ phone\n",
    "    if phone.startswith('55'): # Se não começar com +55, adiciona +55\n",
    "        phone = \"+\"+ phone\n",
    "    if not phone.startswith('+55'):\n",
    "        phone = \"+55\"+ phone\n",
    "    return phone\n",
    "\n",
    "def audit_phone_value(phone):\n",
    "    \"\"\" Audita um número de telefone.\n",
    "    Args:\n",
    "        phone: número de telefone\n",
    "    Returns:\n",
    "        Número corrigido.\n",
    "    \"\"\"\n",
    "    test = phone_type_re.search(phone)\n",
    "    if not test:\n",
    "        phone = update_phone_value(phone)\n",
    "    return phone\n",
    "\n",
    "def audit_phone(osmfile):\n",
    "    \"\"\" Audita todos os telefones de um arquivo OSMFILE.\n",
    "    Args:\n",
    "        osmfile: arquivo XML do OpenStreetMap.\n",
    "    Returns:\n",
    "        Dicionário com todos os telefones bons e um outro dicionário com todos\n",
    "        os telefones ruins.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    phones = set()\n",
    "    bad_phones = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == 'tag':\n",
    "            if 'phone' in elem.attrib['k']:\n",
    "                phone = elem.attrib['v']\n",
    "                test = phone_type_re.search(phone)\n",
    "                if test:\n",
    "                    phones.add(phone)\n",
    "                else:\n",
    "                    bad_phones.add(phone)\n",
    "    osm_file.close()\n",
    "    return phones, bad_phones\n",
    "\n",
    "good_phones, bad_phones = audit_phone(file)\n",
    "\n",
    "print(\"Phones in the wrong format:\")\n",
    "pprint.pprint(bad_phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descobertas**: Aqui realmente encontrou-se vários formatos de números: com espaço, com traço, com DDD entre parênteses sem o código nacional +55, e até em uma frase `'4090-1030 para capitais e regiões metropolitanas e 0800-883-2000 para demais '`. Esse é um campo, portanto, que devemos dar atenção ao passar para o MongoDB.\n",
    "\n",
    "**Correções**: A correção consistiu em formatar todos os números ruins para +55 sem ou com o DDD (sem o zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato do website\n",
    "\n",
    "Novamente, aqui é importante verificar se os atributos `'websites'` estão corretos. Isso também é importante, porque pode ser necesário acessar o link presente nesses campos para fazer alguma coisa, como um screen scraping para\n",
    "obter dados adicionais de alguma tag (como um restaurante ou hospital)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs in the wrong format:\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "''' Auditando os tipos de URL presentes nos campos 'source' e 'website'. Isso também é importante, porque pode \n",
    "ser necesário acessar o link presente nesses campos para fazer alguma coisa, como um screen scraping para\n",
    "obter dados adicionais de alguma tag (como um restaurante ou hospital).'''\n",
    "\n",
    "website_type_re = re.compile(r'^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$', re.IGNORECASE) #Regex para websit\n",
    "\n",
    "def audit_url(osmfile):\n",
    "    \"\"\" Audita todas as URLs um arquivo OSMFILE.\n",
    "    Args:\n",
    "        osmfile: arquivo XML do OpenStreetMap.\n",
    "    Returns:\n",
    "        Dicionário com todas as URLs boas e um outro dicionário com todas\n",
    "        as URLs ruins.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    websites = set()\n",
    "    bad_websites = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == 'tag':\n",
    "            if 'website' in elem.attrib['k']:\n",
    "                site = elem.attrib['v']\n",
    "                test = website_type_re.search(site)\n",
    "                if test:\n",
    "                    websites.add(site)\n",
    "                else:\n",
    "                    bad_websites.add(site)\n",
    "    \n",
    "    osm_file.close()\n",
    "    return websites, bad_websites\n",
    "\n",
    "good_urls, bad_urls = audit_url(file)\n",
    "\n",
    "print(\"URLs in the wrong format:\")\n",
    "pprint.pprint(bad_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Descobertas**: Não foi encontrada nenhuma URL em algum formato estranho. Alguns endereços faltam o `'http://'` ou `'https://'`, outros o `'www'`, mas nada que interfira no acesso ao website.\n",
    "\n",
    "**Correções**: Nenhuma correção necessária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato do e-mail\n",
    "\n",
    "Por fim, aqui é importante verificar se os atributos `'email'` estão corretos. Isso é importante, porque pode ser necesário enviar  um e-mail para o valor presente nesses campos para fazer alguma coisa (como uma notificação de alteração por exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-mails in the wrong format:\n",
      "{'travessacambuí@yahoo.com.br'}\n"
     ]
    }
   ],
   "source": [
    "''' Auditando os tipos de e-mails presentes nos campos 'email'. Isso é importante, porque pode ser necesário enviar \n",
    "um e-mail para o valor presente nesses campos para fazer alguma coisa (como uma notificação de alteração por exemplo).'''\n",
    "\n",
    "email_type_re = re.compile(r'^[A-Za-z0-9\\.\\+_-]+@[A-Za-z0-9\\._-]+\\.[a-zA-Z]*$', re.IGNORECASE) # Regex para validar email\n",
    "\n",
    "def audit_email_value(email):\n",
    "    \"\"\" Atualiza o endereço de email.\n",
    "    Args:\n",
    "        email: edereço de email.\n",
    "    Returns:\n",
    "        Email corrigido.\n",
    "    \"\"\"\n",
    "    nfkd = unicodedata.normalize('NFKD', email) # Unicode normalize transforma um caracter em seu equivalente em latin.\n",
    "    email = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])   \n",
    "    return email\n",
    "\n",
    "def audit_email(osmfile):\n",
    "    \"\"\" Audita todos os emails de um arquivo OSMFILE.\n",
    "    Args:\n",
    "        osmfile: arquivo XML do OpenStreetMap.\n",
    "    Returns:\n",
    "        Dicionário com os emails bons e um outro dicionário com todos\n",
    "        os emails ruins.\n",
    "    \"\"\"\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    emails = set()\n",
    "    bad_emails = set()\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == 'tag':\n",
    "            if 'email' in elem.attrib['k']:\n",
    "                email = elem.attrib['v']\n",
    "                test = email_type_re.search(email)\n",
    "                if test:\n",
    "                    emails.add(email)\n",
    "                else:\n",
    "                    if website_type_re.search(email):\n",
    "                        emails.add(email)\n",
    "                    else:\n",
    "                        bad_emails.add(email)\n",
    "    osm_file.close()\n",
    "    return emails, bad_emails\n",
    "\n",
    "good_emails, bad_emails = audit_email(file)\n",
    "\n",
    "print(\"E-mails in the wrong format:\")\n",
    "pprint.pprint(bad_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descobertas**: Os únicos erros encontrados foram: um acento em um e-mail e um link para o formulário de contato. Em caso de link para formulário de contato, vamos manter, caso queira se realizar um screen scraping para enviar e-mail ou repassar o link para alguém acessar e enviar a mensagem.\n",
    "\n",
    "**Correções**: Como os erros foram poucos e simples, nesse caso é necessário apenas eliminar acentos (já que esse usuário pode ter colocado em outras ocorrências ao longo de outras partes do OSM para arquivos de outras regiões)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Problemas encontrados\n",
    "\n",
    "Os principais problemas encontrados foram nos tipos de ruas e também em alguns nomes, também foram encontrados diversos erros na formatação de telefone e alguns erros em e-mails. As rotinas de correção (*cleanup*) foram implementadas acima, juntamente com as de auditoria dos dados.\n",
    "\n",
    "Agora, portanto, é possível carregar as informações no MongoDB e realizar consultas para descobrir números interessantes da região escolhida. A ideia é focar em pesquisas úteis, como por exemplo, quantidade de restaurantes na região e suas características (para uso interno em aplicações como iFood por exemplo), ou a quantidade de hospitais, heliportos e outros estabelecimentos de assistência e suas características (para uso interno em aplicações como Youse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling com MongoDB\n",
    "\n",
    "### 3.1 Criando o arquivo .json auditado e limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' O primeiro passo aqui é, portanto, transformar o arquivo .osm auditado e limpo em um arquivo .json'''\n",
    "\n",
    "CREATED = [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def handle_email(v):\n",
    "    \"\"\" Formata email.\n",
    "    Args:\n",
    "        v: email não formatado.\n",
    "    Returns:\n",
    "        Retorna email formatado.\n",
    "    \"\"\"\n",
    "    if email_type_re.search(v):\n",
    "        return v\n",
    "    elif website_type_re.search(v):\n",
    "        return v\n",
    "    else:\n",
    "        return audit_email_value(v)\n",
    "\n",
    "def handle_address(node, parts, v):\n",
    "    \"\"\" Formata endereço.\n",
    "    Args:\n",
    "        node: nó.\n",
    "        parts: split do valor do atributo.\n",
    "        v: endereço não formatado.\n",
    "    Returns:\n",
    "        Retorna nó sem nenhuma alteração caso número de partes do split do \n",
    "        atributo seja maior que 2.\n",
    "    \"\"\"\n",
    "    v = v.replace(\"Dr.\", \"Doutor\") # Cleanup do Dr. para Doutor para uniformidade dos nomes.\n",
    "    if len(parts) > 2:\n",
    "        return node\n",
    "    if parts[1] == 'street':\n",
    "        v = update_street_name(v, mapping)\n",
    "    if 'address' not in node:\n",
    "        node['address'] = dict()\n",
    "    node['address'][parts[1]] = v\n",
    "\n",
    "def handle_phone(phone):\n",
    "    \"\"\" Formata número do telefone.\n",
    "    Args:\n",
    "        phone: número do telefone não formatado.\n",
    "    Returns:\n",
    "        Retorna número do telefone formatado.\n",
    "    \"\"\"\n",
    "    phones = re.split(';|,', phone) # separa em múltiplos telefones\n",
    "    updated_phones = list()\n",
    "    for p in phones:\n",
    "        if len(p) == 0: # drop strings vazias\n",
    "            continue\n",
    "        p = audit_phone_value(p)\n",
    "        updated_phones.append(p)\n",
    "    return updated_phones\n",
    "\n",
    "def shape_attribute(node, k, v):\n",
    "    \"\"\" Formata atributos de um determinado nó dada sua chave k e o valor dela.\n",
    "    Args:\n",
    "        node: nó.\n",
    "        k: chave.\n",
    "        v: valor da chave.\n",
    "    Returns:\n",
    "        Retorna um elemento node formatado.\n",
    "    \"\"\"\n",
    "    if k in CREATED:\n",
    "        if 'created' not in node:\n",
    "            node['created'] = dict()\n",
    "        node['created'][k] = v\n",
    "    elif (k == 'lat') or (k == 'lon'):\n",
    "        if 'pos' not in node:\n",
    "            node['pos'] = list()\n",
    "        if k == 'lon':\n",
    "            node['pos'].insert(0, float(v))                \n",
    "        elif k == 'lat':\n",
    "            node['pos'].append(float(v))\n",
    "    else:\n",
    "        node[k] = v\n",
    "    return node\n",
    "\n",
    "def shape_nd(node, tag):\n",
    "    \"\"\" Formata os elementos node_refs de um determinado.\n",
    "    Args:\n",
    "        node: nó.\n",
    "        tag: tag.\n",
    "    Returns:\n",
    "        Retorna um elemento node formatado.\n",
    "    \"\"\"\n",
    "    if 'node_refs' not in node:\n",
    "        node['node_refs'] = list()\n",
    "    node['node_refs'].append(tag.attrib.get('ref'))\n",
    "    return node\n",
    "\n",
    "def shape_tag(node, tag):\n",
    "    \"\"\" Formata uma determinada tag e seus atributos.\n",
    "    Args:\n",
    "        node: nó.\n",
    "        tag: tag.\n",
    "    Returns:\n",
    "        Retorna um elemento node formatado.\n",
    "    \"\"\"\n",
    "    k = tag.attrib.get('k')\n",
    "    v = tag.attrib.get('v')\n",
    "    if problemchars.search(k):\n",
    "        return node\n",
    "    elif ':' in k:\n",
    "        parts = k.split(':')\n",
    "        if parts[0] == 'addr':\n",
    "            node = handle_address(node, parts, v)\n",
    "        elif parts[1] == 'phone' or parts[1] == 'fax':\n",
    "            k = '_'.join(parts)\n",
    "            node[k] = handle_phone(v)\n",
    "        else:\n",
    "            k = '_'.join(parts)\n",
    "            node[k] = v\n",
    "    else:\n",
    "        if k == 'type':\n",
    "            k = 'type_tag'\n",
    "        if k == 'phone':\n",
    "            v = handle_phone(v)\n",
    "        elif k == 'postal_code':\n",
    "            v = update_postal_code(v)\n",
    "        elif k == 'email':\n",
    "            v = handle_email(v)\n",
    "        node[k] = v\n",
    "    return node\n",
    "\n",
    "def handle_helipad_elevation(node):\n",
    "    \"\"\" Formata um elemento helipad.\n",
    "    Args:\n",
    "        node: nó.\n",
    "    Returns:\n",
    "        Retorna um elemento helipad formatado.\n",
    "    \"\"\"\n",
    "    if ('aeroway' in node) and (node['aeroway'] == 'helipad'):\n",
    "        if 'ele' in node: # 'ele' significa elevation\n",
    "            try:\n",
    "                node['ele'] = int(node['ele']) # Converte para int a altitude registrada para o heliporto\n",
    "            except ValueError:\n",
    "                node.pop('ele') # Se não for possível, remove\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\" Formata um elemento XML OSMFILE para um elemento JSON.\n",
    "    Args:\n",
    "        element: elemento XML.\n",
    "    Returns:\n",
    "        Retorna um elemento JSON.\n",
    "    \"\"\"\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node['type'] = element.tag\n",
    "        for key, value in element.attrib.items():\n",
    "            shape_attribute(node, key, value)\n",
    "        for tag in element.iter('nd'):\n",
    "            shape_nd(node, tag)\n",
    "        for tag in element.iter('tag'):\n",
    "            shape_tag(node, tag)\n",
    "        handle_helipad_elevation(node)\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_map(file_in, pretty=False):\n",
    "    \"\"\" Lê um aquivo XML OSMFILE e o transforma em um arquivo JSON.\n",
    "    Args:\n",
    "        file_in: arquivo OSMFILE a ser processado.\n",
    "        pretty: se True, formata visualmente o arquivo JSON resultante,\n",
    "            se False apenas pula de linha a cada registro.\n",
    "    Returns:\n",
    "        Retorna os elementos XML do OSMFILE convertidos em elementos JSON.\n",
    "    \"\"\"\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"wb\", 'utf-8') as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2) + \"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "data = process_map('map.os', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Importando os documentos para o MongoDB\n",
    "\n",
    "Para importar os documentos para o MongoDB, deve-se realizar o seguinte comando:\n",
    "\n",
    "> brew services start mongodb\n",
    "\n",
    "> mongoimport --db project --collection open_street_map --drop --file map.os.json\n",
    "\n",
    "Para acessar, portanto, o Banco de Dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017\") # Acessando a db 'project'\n",
    "db = client['project']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Realizando consultas básicas para verificar a consistência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.open_street_map.find().count() # contagem do número de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.open_street_map.find({'type': 'node'}).count() # contagem das tags node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.open_street_map.find({'type': 'way'}).count() # contagem das tags way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Distinct users:', 'count': 531}]\n"
     ]
    }
   ],
   "source": [
    "def aggregate(db, pipeline):\n",
    "    \"\"\" Agrega os resultados de uma consulta ao banco de dados Mongo.\n",
    "    Args:\n",
    "        db: banco de dados a ser pesquisado.\n",
    "        pipeline: pipeline de consulta.\n",
    "    Returns:\n",
    "        Retorna resultado da consulta.\n",
    "    \"\"\"\n",
    "    return [doc for doc in db.open_street_map.aggregate(pipeline)]\n",
    "\n",
    "distinct_users = [\n",
    "    {'$group': {'_id': '$created.user'}},\n",
    "    {'$group': {'_id': 'Distinct users:', 'count': {'$sum': 1}}}]\n",
    "result = aggregate(db, distinct_users)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observar, o número de usuários foi menor que o que encontramos no XML do OSMFILE. Vamos investigar então."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the162_users = [\n",
    "    {'$group': {'_id': '$created.user', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'_id': 1}},\n",
    "    {'$limit': 531}]\n",
    "result = aggregate(db, the162_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F cajuru\n",
      "Denis Rosa\n",
      "portalaventura\n",
      "elkueb\n",
      "Junior Intervales\n",
      "joao pedro2019\n"
     ]
    }
   ],
   "source": [
    "# Vamos descobrir quem está no arquivo do XML e que não está no MongoDB (arquivo JSON)\n",
    "mongo_users = []\n",
    "\n",
    "for user in result:\n",
    "    mongo_users.append(user['_id'])\n",
    "    \n",
    "for xml_user in users:\n",
    "    i = 0\n",
    "    if xml_user not in mongo_users:\n",
    "        i = 1\n",
    "    if i == 1:\n",
    "        print(xml_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses são os usuários que não estão no MongoDB mas que estão no OSMFILE. Se consultarmos o arquivo XML reparamos que são os usuários que contribuíram criando tags do tipo `'relation'`, as quais, como podemos ver no comando abaixo, decidimos por não carregar no MongoDB. Ou seja, a nossa base de dados indica estar consistente para avançarmos em análises mais interessantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.open_street_map.find({'type': 'relation'}).count() # contagem das tags relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 A parte interessante: consultas aos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, é possível visualizar os 10 usuários que mais contribuiram editando o mapa usado nesse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'patodiez', 'count': 44170},\n",
      " {'_id': 'Gustavo Alves', 'count': 27247},\n",
      " {'_id': '~AR33~', 'count': 26699},\n",
      " {'_id': 'AjBelnuovo', 'count': 17733},\n",
      " {'_id': 'Daniel Assuncao', 'count': 15705},\n",
      " {'_id': 'igorkalju', 'count': 15120},\n",
      " {'_id': 'MCPicoli', 'count': 13899},\n",
      " {'_id': 'PsyLu', 'count': 12942},\n",
      " {'_id': 'Thundercel', 'count': 8108},\n",
      " {'_id': 'kurka', 'count': 6911}]\n"
     ]
    }
   ],
   "source": [
    "top_10_users = [\n",
    "    {'$group': {'_id': '$created.user', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}]\n",
    "result = aggregate(db, top_10_users)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, são contabilizados a quantidade de usuários que contribuiu apenas uma vez para o mapa desse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 1, 'num_users': 112}]\n"
     ]
    }
   ],
   "source": [
    "users_appearing_once = [\n",
    "    {'$group': {'_id': '$created.user', 'count': {'$sum':1}}},\n",
    "    {'$group': {'_id': '$count', 'num_users': {'$sum':1}}},\n",
    "    {'$sort': {'_id': 1}},\n",
    "    {'$limit': 1}]\n",
    "result = aggregate(db, users_appearing_once)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quais as 10 `'amenities'` mais encontradas? É possível observar que a `'amenity'` restaurante (e também tem *fast food*), o que é interessante do ponto de vista de várias aplicações (como iFood, comentado anteriormente). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'restaurant', 'count': 270},\n",
      " {'_id': 'parking', 'count': 264},\n",
      " {'_id': 'school', 'count': 186},\n",
      " {'_id': 'fuel', 'count': 161},\n",
      " {'_id': 'place_of_worship', 'count': 155},\n",
      " {'_id': 'bank', 'count': 137},\n",
      " {'_id': 'telephone', 'count': 100},\n",
      " {'_id': 'fast_food', 'count': 90},\n",
      " {'_id': 'pharmacy', 'count': 87},\n",
      " {'_id': 'clinic', 'count': 55}]\n"
     ]
    }
   ],
   "source": [
    "most_common_amenities = [\n",
    "    {'$match': {'amenity': {'$exists': 1}}},\n",
    "    {'$group': {'_id': '$amenity', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}]\n",
    "result = aggregate(db, most_common_amenities)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E quais os tipos de cozinhas (`'cousines'`) mais comuns? Nessa consulta é possível verificar que cozinha reginal e pizzarias lideram, seguidas por culinária japonesa, churrascaria e culinária italiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'regional', 'count': 35},\n",
      " {'_id': 'pizza', 'count': 30},\n",
      " {'_id': 'japanese', 'count': 15},\n",
      " {'_id': 'barbecue', 'count': 9},\n",
      " {'_id': 'italian', 'count': 8},\n",
      " {'_id': 'burger', 'count': 7},\n",
      " {'_id': 'international', 'count': 6},\n",
      " {'_id': 'chinese', 'count': 6},\n",
      " {'_id': 'steak_house', 'count': 5},\n",
      " {'_id': 'ice_cream', 'count': 4}]\n"
     ]
    }
   ],
   "source": [
    "top_10_cuisines = [\n",
    "    {'$match': {'amenity': 'restaurant', 'cuisine': {'$exists': 1}}},\n",
    "    {'$group': {'_id': '$cuisine', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}]\n",
    "result = aggregate(db, top_10_cuisines)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui são verificados quais restaurantes possuem um telefone de contato registrado no banco de dados. Incrivelmente esse número é bastante pequeno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Rua Coronel Quirino', 'count': 6},\n",
      " {'_id': 'Rua dos Bandeirantes', 'count': 4},\n",
      " {'_id': 'Avenida Coronel Silva Teles', 'count': 4},\n",
      " {'_id': 'Rua Belo Horizonte', 'count': 3},\n",
      " {'_id': 'Avenida Júlio de Mesquita', 'count': 3},\n",
      " {'_id': 'Avenida Albino José Barbosa de Oliveira', 'count': 3},\n",
      " {'_id': 'Rua Barreto Leme', 'count': 2},\n",
      " {'_id': 'Rua João Mendes Júnior', 'count': 2},\n",
      " {'_id': 'Avenida Independência', 'count': 2},\n",
      " {'_id': 'Rua Gustavo Enge', 'count': 2}]\n"
     ]
    }
   ],
   "source": [
    "top_10_streets = [\n",
    "    {'$match': {'amenity': 'restaurant', 'address.street': {'$exists': 1}}},\n",
    "    {'$group': {'_id': '$address.street', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}]\n",
    "result = aggregate(db, top_10_streets)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa consulta, verificamos quais são as ruas com maior número de restaurantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Restaurant with phone stats:', 'count': 22}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_with_phone = [\n",
    "    {'$match': {'amenity': 'restaurant', 'phone': {'$exists': 1}}},\n",
    "    {'$group': {\n",
    "            '_id': 'Restaurant with phone stats:',\n",
    "            'count': {'$sum': 1}}}]\n",
    "result = aggregate(db, restaurant_with_phone)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, se quiséssemos passar os telefones desses restaurantes, para uma equipe entrar em contato, bastaria executar o comando abaixo. E, se quiséssemos passar as localizações dos outros restaurantes bastava fazer a consulta alterando para `'{'$match': {'amenity': 'restaurant', 'phone': {'$exists': 1}}}'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('5aa28ce5d51268e111d2409a'),\n",
      "  'address': {'city': 'Campinas',\n",
      "              'housenumber': '584',\n",
      "              'postcode': '13084-008',\n",
      "              'street': 'Avenida Albino José Barbosa de Oliveira',\n",
      "              'suburb': 'Barao Geraldo'},\n",
      "  'amenity': 'restaurant',\n",
      "  'created': {'changeset': '52805191',\n",
      "              'timestamp': '2017-10-10T20:10:45Z',\n",
      "              'uid': '4176326',\n",
      "              'user': 'mutuka',\n",
      "              'version': '2'},\n",
      "  'cuisine': 'italian',\n",
      "  'id': '1143282936',\n",
      "  'name': \"Estância D'Oliveira\",\n",
      "  'phone': ['+551932895369', '+5532491510'],\n",
      "  'pos': [-47.0787173, -22.8333069],\n",
      "  'type': 'node',\n",
      "  'website': 'http://estanciadoliveirabarao.com.br/'},\n",
      " {'_id': ObjectId('5aa28ce6d51268e111d2d9b9'),\n",
      "  'address': {'housenumber': '39', 'street': 'Rua Belo Horizonte'},\n",
      "  'amenity': 'restaurant',\n",
      "  'created': {'changeset': '11018006',\n",
      "              'timestamp': '2012-03-18T12:15:08Z',\n",
      "              'uid': '397850',\n",
      "              'user': 'Tulio Magno Quites Machado Filho',\n",
      "              'version': '3'},\n",
      "  'cuisine': 'regional',\n",
      "  'id': '1611823609',\n",
      "  'name': 'Restaurante Horto City',\n",
      "  'phone': ['+551938452672'],\n",
      "  'pos': [-47.1967866, -22.8991951],\n",
      "  'type': 'node'},\n",
      " {'_id': ObjectId('5aa28ce6d51268e111d335fc'),\n",
      "  'amenity': 'restaurant',\n",
      "  'created': {'changeset': '10755151',\n",
      "              'timestamp': '2012-02-21T23:48:18Z',\n",
      "              'uid': '397850',\n",
      "              'user': 'Tulio Magno Quites Machado Filho',\n",
      "              'version': '1'},\n",
      "  'cuisine': 'pizza',\n",
      "  'id': '1642528483',\n",
      "  'name': 'Fartutti Pizza',\n",
      "  'phone': ['+551932030101'],\n",
      "  'pos': [-47.0517333, -22.9034838],\n",
      "  'type': 'node'}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_with_phone = [\n",
    "    {'$match': {'amenity': 'restaurant', 'phone': {'$exists': 1}}},\n",
    "    {'$limit': 3}]\n",
    "result = aggregate(db, restaurant_with_phone)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como o número de restaurantes com contato de e-mail no banco de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Restaurant with e-mail stats:', 'count': 1}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_with_email = [\n",
    "    {'$match': {'amenity': 'restaurant', 'email': {'$exists': 1}}},\n",
    "    {'$group': {\n",
    "            '_id': 'Restaurant with e-mail stats:',\n",
    "            'count': {'$sum': 1}}}]\n",
    "result = aggregate(db, restaurant_with_email)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E do número de restaurantes com website no banco de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'Restaurant with website stats:', 'count': 30}]\n"
     ]
    }
   ],
   "source": [
    "restaurant_with_website = [\n",
    "    {'$match': {'amenity': 'restaurant', 'website': {'$exists': 1}}},\n",
    "    {'$group': {\n",
    "            '_id': 'Restaurant with website stats:',\n",
    "            'count': {'$sum': 1}}}]\n",
    "result = aggregate(db, restaurant_with_website)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por curiosidade, a consulta abaixo verifica quais desses restaurantes possuem área para fumante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'no', 'count': 20}, {'_id': 'outside', 'count': 3}]\n"
     ]
    }
   ],
   "source": [
    "smoking = [\n",
    "    {'$match': {'amenity': 'restaurant', 'smoking': {'$exists': 1}}},\n",
    "    {'$group': {'_id': '$smoking', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}}]\n",
    "result = aggregate(db, smoking)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos ver as principais lojas também na região. É possível observar  que há bastante padarias, supermercados e lojas de conveniência, o que também tem relação com possíveis aplicações ligadas ao consumo de alimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': None, 'count': 310755},\n",
      " {'_id': 'supermarket', 'count': 132},\n",
      " {'_id': 'bakery', 'count': 81},\n",
      " {'_id': 'clothes', 'count': 49},\n",
      " {'_id': 'car', 'count': 40},\n",
      " {'_id': 'mall', 'count': 32},\n",
      " {'_id': 'car_repair', 'count': 31},\n",
      " {'_id': 'newsagent', 'count': 27},\n",
      " {'_id': 'hairdresser', 'count': 24},\n",
      " {'_id': 'convenience', 'count': 24}]\n"
     ]
    }
   ],
   "source": [
    "top_10_shop = [\n",
    "    {'$group': {'_id': '$shop', 'count': {'$sum': 1}}},\n",
    "    {'$sort': {'count': -1}},\n",
    "    {'$limit': 10}]\n",
    "result = aggregate(db, top_10_shop)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Aplicação divertida: geolocalização\n",
    "\n",
    "Uma última coisa que podemos fazer, nas verdade uma das coisas mais interessantes que podemos fazer, é utilizar as informações e índices de geolocalização para agregar valor à nossa análise ou aplicação.\n",
    "\n",
    "Campinas não é conhecida por possuir grande atrações turísticas, mas quase todos que visitam ou moram na cidade, acabam ouvindo falar da `'Torre do Castelo'`. \n",
    "\n",
    "Digamos que, em uma visita de amigos eu decida mostrá-la à eles. No entanto, após levá-los até a `'Torre do Castelo'`, como está na hora do almoço, gostaria de saber uma lista de restaurantes próximos. Para isso, poderia realizar a seguinte consulta em minha aplicação para me apresentar os restaurantes mais próximos de onde eu estou. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'cuisine': 'barbecue', 'name': 'Churrascaria Chimarrão'},\n",
      " {'cuisine': 'burger', 'name': 'Big Jack'},\n",
      " {'cuisine': 'japanese', 'name': 'Restaurante Sakae'},\n",
      " {'cuisine': 'pizza', 'name': 'Serata Pizza Bar'},\n",
      " {'cuisine': 'pizza', 'name': 'Villa di Siena'},\n",
      " {'name': 'Panela de Barro'},\n",
      " {'cuisine': 'chicken', 'name': 'Vila del Gali'},\n",
      " {'cuisine': 'pizza', 'name': 'Vila Toscana Pizza e Bar'},\n",
      " {'cuisine': 'ice_cream', 'name': 'Sabor e Sonho'},\n",
      " {'cuisine': 'regional', 'name': \"Casa d'Avó\"}]\n"
     ]
    }
   ],
   "source": [
    "db.open_street_map.create_index([('pos', GEO2D)])\n",
    "\n",
    "my_position = db.open_street_map.find_one({'name': 'Torre do Castelo'})\n",
    "\n",
    "result = db.open_street_map.find(\n",
    "    {'pos': {'$near': my_position['pos']}, 'amenity': 'restaurant'},\n",
    "    {'_id': 0, 'name': 1, 'cuisine': 1, 'address.street': 1}).skip(0).limit(10)\n",
    "\n",
    "pprint.pprint([item for item in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quero também selecionar apenas os restaurantes 100m próximos ao meu local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('5aa28ce6d51268e111d2b8bd'),\n",
      "  'amenity': 'restaurant',\n",
      "  'created': {'changeset': '13700944',\n",
      "              'timestamp': '2012-10-31T15:37:45Z',\n",
      "              'uid': '99811',\n",
      "              'user': 'Camponez',\n",
      "              'version': '2'},\n",
      "  'cuisine': 'barbecue',\n",
      "  'distance': 0.04934416504020776,\n",
      "  'id': '1588346110',\n",
      "  'name': 'Churrascaria Chimarrão',\n",
      "  'pos': [-47.0763283, -22.8901036],\n",
      "  'type': 'node'},\n",
      " {'_id': ObjectId('5aa28ce6d51268e111d2c931'),\n",
      "  'amenity': 'restaurant',\n",
      "  'created': {'changeset': '13700944',\n",
      "              'timestamp': '2012-10-31T15:38:00Z',\n",
      "              'uid': '99811',\n",
      "              'user': 'Camponez',\n",
      "              'version': '2'},\n",
      "  'cuisine': 'burger',\n",
      "  'distance': 0.052290421274735405,\n",
      "  'id': '1605858810',\n",
      "  'name': 'Big Jack',\n",
      "  'pos': [-47.0763356, -22.8898775],\n",
      "  'type': 'node'}]\n"
     ]
    }
   ],
   "source": [
    "top_100m_near = [\n",
    "    { \"$geoNear\": {\n",
    "        \"near\": my_position['pos'],\n",
    "        \"maxDistance\": 0.1/6378, # 0.1 km (ou 100m) mais próximos\n",
    "        \"spherical\": \"true\",\n",
    "        \"distanceField\": \"distance\",\n",
    "        \"distanceMultiplier\": 6378, # diâmetro da Terra em km\n",
    "        \"query\": {'amenity': 'restaurant'}\n",
    "    }}]\n",
    "result = aggregate(db, top_100m_near)\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto a Churrascaria Chimarrão (49m de distância) quanto o Big Jack (52m de distância) parecem boas pedidas! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reflexão\n",
    "\n",
    "### 4.1 Completude e precisão.\n",
    "\n",
    "O maior problema encontrado aqui é a falta de completude dos dados e de precisão. E no caso dessa aplicação, quanto maior completude alcançarmos, maior será o problema de precisão, pois informações de contato, bem como o nome do próprio estabelecimento, podem mudar com alguma frequência. Mas a análise ganharia bastante quanto mais completo e preciso fossem os dados do OSMFILE.\n",
    "\n",
    "#### Solução: criação de um mecanismo de gamificação para incentivar a contribuição dos usuários\n",
    "\n",
    "- Benefícios:   \n",
    "    - Um sistema de gamification, estilo Waze, poderia contribuir muito para o aumento da completude e precisão das informações.\n",
    "    - Também manteria o sistema bastante atualizado.\n",
    "\n",
    "\n",
    "- Problemas:     \n",
    "    - Encontrar um sistema de gamification que funciona é complicado, pode dar certo de primeira como pode ser um desatre completo (por isso Agile é altamente recomendado aqui).\n",
    "    - Teria que conhecer melhor os usuários do OSM. Se o perfil deles não for o de pessoas que aceitam gamification, pode acabar dando errado.\n",
    "    \n",
    "#### Solução: integração com APIs externas para imputação de dados ausentes\n",
    "\n",
    "- Benefícios:   \n",
    "    - É uma forma bastante rápida de resolver o problema de completude e precisão.\n",
    "    - Por exemplo, usar a própria API do próprio Google Maps.\n",
    "\n",
    "\n",
    "- Problemas:     \n",
    "    - O Google cobra pelo acesso à API do Maps dependendo do volume de requisições.\n",
    "    - Cada solução tem suas peculiaridades, e no longo prazo manter essa base de código de integração com terceiros poderia ser um grande problema.\n",
    "\n",
    "\n",
    "### 4.2 Open Street Map poderia adicionar validador de telefone, código postal, e-mail, e website\n",
    "\n",
    "Com uma ação simples, como oferecer no frontend (e no backend) do Open Street Map funcionalidades de validação dos inputs de telefone, código postal, e-mail, e website pelos usuários contribuiria bastante em manter os dados consistentes e, principalmente, uniformes.\n",
    "\n",
    "#### Solução: validação de campos\n",
    "\n",
    "- Benefícios:   \n",
    "    - Melhor solução, criar validadores para os principais campos.\n",
    "\n",
    "\n",
    "- Problemas:     \n",
    "    - Pode inibir o uso do sistema pelos usuários se não for bem implementado.\n",
    "\n",
    "#### Solução: validação do código postal com o WebService dos Correios\n",
    "\n",
    "- Benefícios:   \n",
    "    - Todos os códigos postais em território nacional estariam no mesmo formato.\n",
    "\n",
    "\n",
    "- Problemas:     \n",
    "    - Se pensar do ponto de vista do OSM não seria a melhor solução ainda, pois funcionaria no Brasil. Mas e nos demais países? E integrar com a API de código postal de cada país (onde houver) vai certamente ser um ponto desafiador a longo prazo para manutenção de código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusão\n",
    "\n",
    "Com pode-se perceber, e que já era previsto, os dados inseridos por pessoas quase sempre terão inconsistências e problemas de completude. E mesmo que uma grande parte dela seja inserida por bots, diferentes bots podem inserir dados usando padrões diferentes e a inconsistência permanece. Por outro lado, essa liberdade na entrada de dados confere muita flexibilidade aos usuários e, por isso, a representação do mapa pode ser ainda mais fiel ao mundo real.\n",
    "\n",
    "A limpeza foi bastante útil para análises posteriores, validando a geolocalização dos elementos, bem como validando e formatando os campos de contatos e endereço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "> Data cleansing, https://en.wikipedia.org/wiki/Data_cleansing\n",
    "\n",
    "> Google Python Style Guide, https://google.github.io/styleguide/pyguide.html\n",
    "\n",
    "> Google Python Style Guide (Comments Section), https://google.github.io/styleguide/pyguide.html?showone=Comments#Comments\n",
    "\n",
    "> GeoNear, https://docs.mongodb.com/manual/reference/command/geoNear/#examples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
